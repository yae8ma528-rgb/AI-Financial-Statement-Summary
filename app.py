import streamlit as st
import time
import os
import uuid
import prompts
import utils
import gemini_logic
import help
import update_history
from google.genai import errors

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ±ºç®—æ›¸ã¾ã¨ã‚Bot",
    page_icon="ğŸ¤–",
    layout="centered",
)

# æ—¥æœ¬èªè¨­å®šãƒãƒƒã‚¯
utils.setup_japanese_language()

st.title("æ±ºç®—æ›¸ã¾ã¨ã‚Bot v0.3.3Î²")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
client = gemini_logic.get_gemini_client()

if "current_page" not in st.session_state:
    st.session_state.current_page = "main"

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¡ãƒ‹ãƒ¥ãƒ¼ ---
with st.sidebar:
    st.header("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    
    # ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³
    if st.button("ãƒ›ãƒ¼ãƒ "):
        st.session_state.current_page = "main"
        st.rerun()

    if st.button("ä½¿ã„æ–¹"):
        st.session_state.current_page = "help"
        st.rerun()
        
    if st.button("æ›´æ–°å±¥æ­´"):
        st.session_state.current_page = "history"
        st.rerun()

    st.divider()

    if st.button("åˆ†æã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.confirm_reset = True

    if st.session_state.get("confirm_reset"):
        st.warning("æœ¬å½“ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã‹ï¼Ÿ\nä¼šè©±å±¥æ­´ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å‰Šé™¤"):
                # ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if st.session_state.get("uploaded_gemini_file_names"):
                    gemini_logic.delete_files_from_gemini(client, st.session_state.uploaded_gemini_file_names)
                    st.sidebar.success("ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨ã¦å‰Šé™¤ã—ã¾ã—ãŸ")
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– (current_pageã¯ç¶­æŒã™ã‚‹ã‹ã€mainã«æˆ»ã™ã‹ã€‚ã“ã“ã§ã¯mainã«æˆ»ã™)
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                
                # æ–°ã—ã„uploader_keyã‚’è¨­å®šã—ã¦ãƒªã‚»ãƒƒãƒˆ
                st.session_state.uploader_key = str(uuid.uuid4())
                st.session_state.current_page = "main"
                st.rerun()
        with col2:
            if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                st.session_state.confirm_reset = False
                st.rerun()

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– (å‰Šé™¤å¾Œã‚‚å†ç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«é…ç½®) ---
# ä»–ã®session stateåˆæœŸåŒ–ã¯ä¸‹ã«ã‚ã‚‹ã®ã§current_pageã ã‘ã“ã“ã§ã‚‚ç¢ºèªï¼ˆãƒªã‚»ãƒƒãƒˆç›´å¾Œç”¨ï¼‰
if "current_page" not in st.session_state:
    st.session_state.current_page = "main"
if "chat_session" not in st.session_state:
    st.session_state.chat_session = None
if "summary_done" not in st.session_state:
    st.session_state.summary_done = False
if "messages" not in st.session_state:
    st.session_state.messages = []
if "uploaded_gemini_file_names" not in st.session_state:
    st.session_state.uploaded_gemini_file_names = []
if "analysis_mode" not in st.session_state:
    st.session_state.analysis_mode = None 
if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = str(uuid.uuid4())

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def set_analysis_mode(mode):
    st.session_state.analysis_mode = mode

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.session_state.current_page == "main":
    uploaded_files = st.file_uploader(
        "æ±ºç®—æ›¸(PDF or HTML)ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚", 
        type=["pdf", "htm", "html"], 
        key=st.session_state.uploader_key, 
        accept_multiple_files=True
    )

    if uploaded_files and not st.session_state.summary_done:
        
        # å‡¦ç†å¯¾è±¡ã®æ±ºå®šã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
        should_process = False
        target_prompt = None
        
        # 1ãƒ•ã‚¡ã‚¤ãƒ«: è‡ªå‹•å®Ÿè¡Œ
        if len(uploaded_files) == 1:
            should_process = True
            target_prompt = prompts.PROMPT_FINANCIAL_SUMMARY
        
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«: ãƒ¢ãƒ¼ãƒ‰é¸æŠå¾…æ©Ÿ
        else:
            # ãƒ¢ãƒ¼ãƒ‰æœªé¸æŠæ™‚ã¯ãƒœã‚¿ãƒ³è¡¨ç¤º
            if st.session_state.analysis_mode is None:
                st.info(f"{len(uploaded_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚å®Ÿè¡Œã™ã‚‹åˆ†æã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                col1, col2 = st.columns(2)
                col1.button("1ç¤¾ã®é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", on_click=set_analysis_mode, args=("trend",))
                col2.button("è¤‡æ•°ç¤¾ã®æ¯”è¼ƒ", on_click=set_analysis_mode, args=("compare",))
            
            # ãƒ¢ãƒ¼ãƒ‰é¸æŠæ¸ˆã¿
            elif st.session_state.analysis_mode:
                should_process = True
                if st.session_state.analysis_mode == "trend":
                    target_prompt = prompts.PROMPT_TREND_ANALYSIS
                elif st.session_state.analysis_mode == "compare":
                    target_prompt = prompts.PROMPT_COMPANY_COMPARISON

        # --- åˆ†æå®Ÿè¡Œãƒ•ãƒ­ãƒ¼ ---
        if should_process and target_prompt:
            with st.spinner("AIãŒè§£æä¸­ã§ã™..."):
                
                contents_to_send = []
                
                for u_file in uploaded_files:
                    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                    processed_data = utils.process_uploaded_file(u_file)
                    
                    if processed_data:
                        if processed_data["type"] == "pdf":
                            # PDFã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦
                             try:
                                uploaded_gemini_file = gemini_logic.upload_file_to_gemini(
                                    client, 
                                    processed_data["content"], # ã“ã“ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                                    processed_data["display_name"]
                                )
                                contents_to_send.append(uploaded_gemini_file)
                                st.session_state.uploaded_gemini_file_names.append(uploaded_gemini_file.name)
                             finally:
                                 # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                                 if processed_data["tmp_path"] and os.path.exists(processed_data["tmp_path"]):
                                     os.remove(processed_data["tmp_path"])

                        elif processed_data["type"] == "html":
                            # HTMLãƒ†ã‚­ã‚¹ãƒˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã¤ã‘ã¦è¿½åŠ 
                            clean_text = f"--- File: {processed_data['display_name']} ---\n{processed_data['content']}"
                            contents_to_send.append(clean_text)
                
                if contents_to_send:
                    # ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ— (æœ€å¤§3å›)
                    max_retries = 3
                    for attempt in range(max_retries):
                        try:
                            # APIå‘¼ã³å‡ºã— (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
                            chat, response_stream, used_model = gemini_logic.send_message_stream_with_fallback(
                                client,
                                contents_to_send,
                                target_prompt,
                                prompts.SYSTEM_INSTRUCTION
                            )
                            
                            if chat and response_stream:
                                st.session_state.chat_session = chat
                                st.session_state.current_model = used_model
                                
                                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                                with st.chat_message("assistant"):
                                    # st.write_stream ã¯ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å®Œäº†å¾Œã«å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
                                    # gemini_logicå´ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾æ¸¡ã™
                                    full_response_text = st.write_stream(response_stream)
                                
                                # å±¥æ­´ä¿å­˜
                                st.session_state.messages.append({"role": "assistant", "content": full_response_text})
                                st.session_state.summary_done = True
                                st.rerun()
                                break # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                            else:
                                if attempt == max_retries - 1:
                                    st.error("è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        
                        except (errors.ClientError, errors.ServerError) as e:
                            if attempt < max_retries - 1:
                                st.warning(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†è©¦è¡Œã—ã¾ã™... ({attempt+1}/{max_retries})")
                                time.sleep(2)
                            else:
                                st.error(f"ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šè§£æã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

    # --- ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ä»–ã«èããŸã„ã“ã¨ã¯ï¼Ÿ"):
        if not st.session_state.chat_session:
            st.toast("å…ˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚", icon="âš ï¸")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    current_chat = st.session_state.chat_session
                    max_retries = 3
                    
                    for attempt in range(max_retries):
                        try:
                            response_stream = None
                            
                            # 1å›ç›®ã¯æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§è©¦è¡Œ
                            if attempt == 0:
                                response_stream = current_chat.send_message_stream(prompt)
                                # ç”Ÿã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã§ãƒ©ãƒƒãƒ—
                                clean_stream = gemini_logic.clean_stream_generator(response_stream)
                            
                            # 2å›ç›®ä»¥é™ï¼ˆãƒªãƒˆãƒ©ã‚¤ï¼‰ã¯æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œã‚Šç›´ã™
                            else:
                                st.warning(f"æ··é›‘ã—ã¦ã„ã¾ã™ã€‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å›ç·šã§å†æ¥ç¶šä¸­... ({attempt}/{max_retries-1})")
                                time.sleep(2)
                                
                                old_history = current_chat.history
                                new_chat, new_stream, used_model = gemini_logic.send_message_stream_with_fallback(
                                    client,
                                    content=[], 
                                    prompt=prompt,
                                    system_instruction=prompts.SYSTEM_INSTRUCTION,
                                    previous_history=old_history
                                )
                                
                                if new_chat and new_stream:
                                    st.session_state.chat_session = new_chat
                                    st.session_state.current_model = used_model
                                    current_chat = new_chat # ãƒ«ãƒ¼ãƒ—å†…ã§ã®å‚ç…§ç”¨
                                    clean_stream = new_stream # ã“ã‚Œã¯æ—¢ã«ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ï¼ˆfallbacké–¢æ•°æˆ»ã‚Šå€¤ï¼‰
                                else:
                                    raise Exception("Retry session creation failed")

                            with st.chat_message("assistant"):
                                full_response_text = st.write_stream(clean_stream)
                            
                            st.session_state.messages.append({"role": "assistant", "content": full_response_text})
                            break # æˆåŠŸçµ‚äº†

                        except (errors.ClientError, errors.ServerError) as e:
                            # 429/503ã¯ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡
                            if e.code in [429, 503] or "429" in str(e) or "503" in str(e):
                                if attempt == max_retries - 1:
                                    st.error(f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚µãƒ¼ãƒãƒ¼ãŒå¤§å¤‰æ··é›‘ã—ã¦ãŠã‚Šå¿œç­”ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚({e})")
                            else:
                                # ãã®ä»–ã®APIã‚¨ãƒ©ãƒ¼ã¯å³çµ‚äº†
                                st.error(f"APIã‚¨ãƒ©ãƒ¼: {e}")
                                break
                                
                        except Exception as e:
                             if attempt == max_retries - 1:
                                st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
                             # ãã‚Œä»¥å¤–ã¯ãƒªãƒˆãƒ©ã‚¤ç¶šè¡Œ

                except Exception as e:
                    st.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

elif st.session_state.current_page == "help":
    st.header("ä½¿ã„æ–¹")
    st.markdown(help.HELP_MARKDOWN)

elif st.session_state.current_page == "history":
    st.header("æ›´æ–°å±¥æ­´")

    st.markdown(update_history.UPDATE_HISTORY_MARKDOWN)

import streamlit as st
import time
import os
import uuid
import platform
import prompts
import utils
import gemini_logic
import help
from google.genai import errors

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="æ±ºç®—æ›¸ã¾ã¨ã‚Bot",
    page_icon="ğŸ¤–",
    layout="centered",
)

# æ—¥æœ¬èªè¨­å®šãƒãƒƒã‚¯
utils.setup_japanese_language()

st.title("æ±ºç®—æ›¸ã¾ã¨ã‚Bot v0.3.1Î²")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—
client = gemini_logic.get_gemini_client()

if "current_page" not in st.session_state:
    st.session_state.current_page = "main"

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¡ãƒ‹ãƒ¥ãƒ¼ ---
with st.sidebar:
    st.header("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    
    # ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³
    if st.session_state.current_page == "main":
        if st.button("ä½¿ã„æ–¹ã‚’è¦‹ã‚‹"):
            st.session_state.current_page = "help"
            st.rerun()
    else:
        if st.button("åˆ†æã«æˆ»ã‚‹"):
            st.session_state.current_page = "main"
            st.rerun()

    st.divider()

    if st.button("åˆ†æã‚’ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.confirm_reset = True

    if st.session_state.get("confirm_reset"):
        st.warning("æœ¬å½“ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã‹ï¼Ÿ\nä¼šè©±å±¥æ­´ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å‰Šé™¤"):
                # ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if st.session_state.get("uploaded_gemini_file_names"):
                    gemini_logic.delete_files_from_gemini(client, st.session_state.uploaded_gemini_file_names)
                    st.sidebar.success("ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨ã¦å‰Šé™¤ã—ã¾ã—ãŸ")
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– (current_pageã¯ç¶­æŒã™ã‚‹ã‹ã€mainã«æˆ»ã™ã‹ã€‚ã“ã“ã§ã¯mainã«æˆ»ã™)
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                
                # æ–°ã—ã„uploader_keyã‚’è¨­å®šã—ã¦ãƒªã‚»ãƒƒãƒˆ
                st.session_state.uploader_key = str(uuid.uuid4())
                st.session_state.current_page = "main"
                st.rerun()
        with col2:
            if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                st.session_state.confirm_reset = False
                st.rerun()

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– (å‰Šé™¤å¾Œã‚‚å†ç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«é…ç½®) ---
# ä»–ã®session stateåˆæœŸåŒ–ã¯ä¸‹ã«ã‚ã‚‹ã®ã§current_pageã ã‘ã“ã“ã§ã‚‚ç¢ºèªï¼ˆãƒªã‚»ãƒƒãƒˆç›´å¾Œç”¨ï¼‰
if "current_page" not in st.session_state:
    st.session_state.current_page = "main"
if "chat_session" not in st.session_state:
    st.session_state.chat_session = None
if "summary_done" not in st.session_state:
    st.session_state.summary_done = False
if "messages" not in st.session_state:
    st.session_state.messages = []
if "uploaded_gemini_file_names" not in st.session_state:
    st.session_state.uploaded_gemini_file_names = []
if "analysis_mode" not in st.session_state:
    st.session_state.analysis_mode = None 
if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = str(uuid.uuid4())

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def set_analysis_mode(mode):
    st.session_state.analysis_mode = mode

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.session_state.current_page == "main":
    uploaded_files = st.file_uploader(
        "æ±ºç®—æ›¸(PDF or HTML)ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚", 
        type=["pdf", "htm", "html"], 
        key=st.session_state.uploader_key, 
        accept_multiple_files=True
    )

    if uploaded_files and not st.session_state.summary_done:
        
        # å‡¦ç†å¯¾è±¡ã®æ±ºå®šã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
        should_process = False
        target_prompt = None
        
        # 1ãƒ•ã‚¡ã‚¤ãƒ«: è‡ªå‹•å®Ÿè¡Œ
        if len(uploaded_files) == 1:
            should_process = True
            target_prompt = prompts.PROMPT_FINANCIAL_SUMMARY
        
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«: ãƒ¢ãƒ¼ãƒ‰é¸æŠå¾…æ©Ÿ
        else:
            # ãƒ¢ãƒ¼ãƒ‰æœªé¸æŠæ™‚ã¯ãƒœã‚¿ãƒ³è¡¨ç¤º
            if st.session_state.analysis_mode is None:
                st.info(f"{len(uploaded_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚å®Ÿè¡Œã™ã‚‹åˆ†æã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                col1, col2 = st.columns(2)
                col1.button("1ç¤¾ã®é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", on_click=set_analysis_mode, args=("trend",))
                col2.button("è¤‡æ•°ç¤¾ã®æ¯”è¼ƒ", on_click=set_analysis_mode, args=("compare",))
            
            # ãƒ¢ãƒ¼ãƒ‰é¸æŠæ¸ˆã¿
            elif st.session_state.analysis_mode:
                should_process = True
                if st.session_state.analysis_mode == "trend":
                    target_prompt = prompts.PROMPT_TREND_ANALYSIS
                elif st.session_state.analysis_mode == "compare":
                    target_prompt = prompts.PROMPT_COMPANY_COMPARISON

        # --- åˆ†æå®Ÿè¡Œãƒ•ãƒ­ãƒ¼ ---
        if should_process and target_prompt:
            with st.spinner("AIãŒè§£æä¸­ã§ã™..."):
                
                contents_to_send = []
                
                for u_file in uploaded_files:
                    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                    processed_data = utils.process_uploaded_file(u_file)
                    
                    if processed_data:
                        if processed_data["type"] == "pdf":
                            # PDFã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦
                             try:
                                uploaded_gemini_file = gemini_logic.upload_file_to_gemini(
                                    client, 
                                    processed_data["content"], # ã“ã“ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                                    processed_data["display_name"]
                                )
                                contents_to_send.append(uploaded_gemini_file)
                                st.session_state.uploaded_gemini_file_names.append(uploaded_gemini_file.name)
                             finally:
                                 # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                                 if processed_data["tmp_path"] and os.path.exists(processed_data["tmp_path"]):
                                     os.remove(processed_data["tmp_path"])

                        elif processed_data["type"] == "html":
                            # HTMLãƒ†ã‚­ã‚¹ãƒˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã¤ã‘ã¦è¿½åŠ 
                            clean_text = f"--- File: {processed_data['display_name']} ---\n{processed_data['content']}"
                            contents_to_send.append(clean_text)
                
                if contents_to_send:
                    # APIå‘¼ã³å‡ºã— (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
                    chat, response_stream, used_model = gemini_logic.send_message_stream_with_fallback(
                        client,
                        contents_to_send,
                        target_prompt,
                        prompts.SYSTEM_INSTRUCTION
                    )
                    
                    if chat and response_stream:
                        st.session_state.chat_session = chat
                        st.session_state.current_model = used_model
                        
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                        with st.chat_message("assistant"):
                            # st.write_stream ã¯ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å®Œäº†å¾Œã«å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
                            # gemini_logicå´ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ã¦ã„ã‚‹ã®ã§ãã®ã¾ã¾æ¸¡ã™
                            full_response_text = st.write_stream(response_stream)
                        
                        # å±¥æ­´ä¿å­˜
                        st.session_state.messages.append({"role": "assistant", "content": full_response_text})
                        st.session_state.summary_done = True
                        st.rerun()
                    else:
                        st.error("è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ä»–ã«èããŸã„ã“ã¨ã¯ï¼Ÿ"):
        if not st.session_state.chat_session:
            st.toast("å…ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚", icon="âš ï¸")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    current_chat = st.session_state.chat_session
                    try:
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡
                        response_stream = current_chat.send_message_stream(prompt)
                        
                        with st.chat_message("assistant"):
                             # gemini_logicå´ã§ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã ãŒã€ã“ã“ã¯ç›´æ¥ stream ã‚’æŒã£ã¦ã„ã‚‹
                             # ç›´æ¥callã—ãŸå ´åˆ(line 181)ã€response_streamã¯ç”Ÿã®iterator
                             # ãªã®ã§ã“ã“ã§ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦
                             def clean_gen(s):
                                for c in s:
                                    if c.text: yield c.text.replace("\\n", "\n")
                             
                             full_response_text = st.write_stream(clean_gen(response_stream))
                        
                        st.session_state.messages.append({"role": "assistant", "content": full_response_text})

                    except errors.ClientError as e:
                         # 429ç­‰ã®å ´åˆã€æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒªãƒˆãƒ©ã‚¤ã‚’è©¦ã¿ã‚‹
                         if e.code == 429 or "429" in str(e):
                            st.warning("ãƒ¢ãƒ‡ãƒ«ãŒæ··é›‘ã—ã¦ã„ã¾ã™ã€‚åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œã—ã¾ã™...")
                            time.sleep(1)
                            
                            # å±¥æ­´å–å¾—
                            old_history = current_chat.history
                            
                            # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒªãƒˆãƒ©ã‚¤ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
                            new_chat, response_stream, used_model = gemini_logic.send_message_stream_with_fallback(
                                client,
                                content=[], # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãªã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
                                prompt=prompt,
                                system_instruction=prompts.SYSTEM_INSTRUCTION,
                                previous_history=old_history
                            )
                            
                            if new_chat and response_stream:
                                st.session_state.chat_session = new_chat
                                st.session_state.current_model = used_model
                                
                                with st.chat_message("assistant"):
                                    full_response_text = st.write_stream(response_stream)
                                
                                st.session_state.messages.append({"role": "assistant", "content": full_response_text})
                            else:
                                st.error("å†è©¦è¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                         else:
                            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

                except Exception as e:
                    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

elif st.session_state.current_page == "help":
    st.header("ä½¿ã„æ–¹")
    st.markdown(help.HELP_MARKDOWN)